<h1 style="text-align:justify;">Repository with data mining methodologies</h1>
<h4 style="text-align:justify;">In this repository, you'll find my approach to generating solutions for data mining projects. I follow the widely-used CRISP-DM methodology, as outlined in the image below. It provides an overview of the typical phases of a project, the tasks associated with each phase, and an explanation of how these tasks interconnect.</h4>
<figure class="image" data-ckbox-resource-id="sQTij5pLY_TL">
    <picture>
        <source srcset="https://ckbox.cloud/ce2cf76480eda7687bf6/assets/sQTij5pLY_TL/images/80.webp 80w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/sQTij5pLY_TL/images/160.webp 160w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/sQTij5pLY_TL/images/240.webp 240w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/sQTij5pLY_TL/images/320.webp 320w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/sQTij5pLY_TL/images/400.webp 400w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/sQTij5pLY_TL/images/480.webp 480w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/sQTij5pLY_TL/images/514.webp 514w" type="image/webp" sizes="(max-width: 514px) 100vw, 514px"><img src="https://ckbox.cloud/ce2cf76480eda7687bf6/assets/sQTij5pLY_TL/images/514.jpeg" width="514" height="514">
    </picture>
</figure>
<h5 style="text-align:justify;">1. Business Understanding<br>&nbsp;</h5>
<ul>
    <li>
        <p style="text-align:justify;">Determine the main objectives of the organization related to the project;</p>
    </li>
    <li>
        <p style="text-align:justify;">Analyze the current scenario and identify challenges or opportunities related to treasury management;</p>
    </li>
    <li>
        <p style="text-align:justify;">Conduct an in-depth analysis of treasury management concepts, identifying challenges related to forecasting invoice payment dates;</p>
    </li>
    <li>
        <p style="text-align:justify;">Clearly define the objectives of data mining in the context of treasury management;</p>
    </li>
    <li>
        <p style="text-align:justify;">Develop a detailed plan outlining the phases and tasks to be carried out during the project.</p>
    </li>
</ul>
<h5 style="text-align:justify;">2. Data Understanding<br>&nbsp;</h5>
<ul>
    <li>
        <p style="text-align:justify;">Description of the data (meaning of the variables, number of variables and records, meaning of the records, among others);</p>
    </li>
    <li>
        <p style="text-align:justify;">Data exploration (graphical and statistical analysis, identification of correlations);</p>
    </li>
    <li>
        <p style="text-align:justify;">Data quality verification (identification of possible errors, such as missing values, outliers, or inconsistent data);&nbsp;</p>
    </li>
    <li>
        <p style="text-align:justify;">Analyze the prevalence and nature of the identified errors</p>
        <p style="text-align:justify;">&nbsp;</p>
    </li>
</ul>
<p style="text-align:justify;"><strong>3. Data Preparation</strong><br>&nbsp;</p>
<ul>
    <li>
        <p style="text-align:justify;"><strong>Data cleaning:&nbsp;</strong></p>
        <ul>
            <li>
                <p style="text-align:justify;">Selection of relevant data for analysis, considering its importance to the project objectives;</p>
            </li>
            <li>
                <p style="text-align:justify;">Removal or imputation of data and selection of the best estimator, if necessary);</p>
            </li>
            <li>
                <p style="text-align:justify;">Cleaning incorrect, incomplete, or duplicated data;</p>
            </li>
        </ul>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Data transformation:</strong></p>
        <ul>
            <li>
                <p style="text-align:justify;">Feature engineering: Creating new aggregated or derived features from existing data to uncover insights;</p>
            </li>
            <li>
                <p style="text-align:justify;">Encoding categorical data: Converting text categories to numbers for modeling;</p>
            </li>
            <li>
                <p style="text-align:justify;">Data normalization or scaling: Standardizing data ranges to enable meaningful comparisons.</p>
            </li>
            <li>
                <p style="text-align:justify;">Anomaly Detection</p>
            </li>
            <li>
                <p style="text-align:justify;">Combining data from different sources</p>
            </li>
            <li>
                <p style="text-align:justify;">Anonymizing personal information</p>
            </li>
            <li>
                <p style="text-align:justify;">Converting data types</p>
            </li>
            <li>
                <p style="text-align:justify;">Structuring unstructured data</p>
            </li>
            <li>
                <p style="text-align:justify;"><strong>&amp; Others</strong></p>
            </li>
        </ul>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Data integration</strong> (grouping data, combining information from various columns);</p>
        <ul>
            <li>
                <p style="text-align:justify;">Feature selection: Selecting the most relevant features to avoid over-fitting.</p>
            </li>
            <li>
                <p style="text-align:justify;">Addressing class imbalance: Re-sampling if one target class dominates to prevent bias.</p>
            </li>
            <li>
                <p style="text-align:justify;"><strong>&amp; Others</strong></p>
            </li>
        </ul>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Data formatting</strong>.</p>
    </li>
    <li>
        <p style="text-align:justify;">Data Splitting: Divide the data into three sets — training data, validation data, and test data.</p>
    </li>
</ul>
<h6 style="text-align:justify;">4. Data Modeling for Machine Learning</h6>
<p style="text-align:justify;">Data Modeling is a process of the Crisp-dm methodology that aims to estimate the inherent structure of a dataset to reveal valuable patterns and predict unseen instances. Remember, Crisp-dm is an interactive process. This step needs to be complemented by the previous step (data preparation).</p>
<p style="text-align:justify;">At this step we need to choose the correct machine learning algorithms according to our objectives. In the following diagram we can see all the possible options:&nbsp;</p>
<figure class="image" data-ckbox-resource-id="qeaEbSmAbOcG">
    <picture>
        <source srcset="https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/288.webp 288w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/576.webp 576w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/864.webp 864w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/1152.webp 1152w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/1440.webp 1440w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/1728.webp 1728w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/2016.webp 2016w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/2304.webp 2304w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/2592.webp 2592w,https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/2880.webp 2880w" type="image/webp" sizes="(max-width: 2880px) 100vw, 2880px"><img src="https://ckbox.cloud/ce2cf76480eda7687bf6/assets/qeaEbSmAbOcG/images/2880.png" width="2880" height="1304">
    </picture>
</figure>
<p style="text-align:justify;"><strong>Supervised Learning:</strong></p>
<p style="text-align:justify;">Supervised learning can be categorized into two main types:&nbsp;</p>
<ul>
    <li>
        <p style="text-align:justify;">Classification: This involves predicting a discrete label, such as identifying an email as spam or not spam.</p>
    </li>
    <li>
        <p style="text-align:justify;">Regression: This involves predicting a continuous value, like forecasting the price of a house based on its features.</p>
        <p style="text-align:justify;"><strong>Note</strong>: The category depends on the target variable. The predictors can be continuous or discrete (or both) depending on the model selected.&nbsp;</p>
    </li>
</ul>
<p style="text-align:justify;">&nbsp;</p>
<p style="text-align:justify;"><a target="_blank" rel="noopener noreferrer" href="https://www.simplilearn.com/10-algorithms-machine-learning-engineers-need-to-know-article">Popular Supervided Learning Algorithms:</a></p>
<ul>
    <li>
        <p style="text-align:justify;">Linear Regression: Used for predicting continuous outcomes. It models the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data.</p>
    </li>
    <li>
        <p style="text-align:justify;">Logistic Regression: Used for binary classification tasks (e.g., predicting yes/no outcomes). It estimates probabilities using a logistic function.</p>
    </li>
    <li>
        <p style="text-align:justify;">Decision Trees: These models predict the value of a target variable by learning simple decision rules inferred from the data features.</p>
    </li>
    <li>
        <p style="text-align:justify;">Random Forests: An ensemble of decision trees, typically used for classification and regression, improving model accuracy and overfitting control.</p>
    </li>
    <li>
        <p style="text-align:justify;">Support Vector Machines (SVM): Effective in high-dimensional spaces, SVM is primarily used for classification but can also be used for regression.</p>
    </li>
    <li>
        <p style="text-align:justify;">Neural Networks: These are powerful models that can capture complex non-linear relationships. They are widely used in deep learning applications.</p>
    </li>
</ul>
<p style="text-align:justify;">&nbsp;</p>
<p style="text-align:justify;"><a target="_blank" rel="noopener noreferrer" href="https://www.restack.io/p/supervised-learning-answer-advanced-algorithms-cat-ai">Advanced Supervised Learning Algorithms</a></p>
<p style="text-align:justify;"><br><strong>Hyper-Parameter Optimization Techniques:</strong></p>
<ul>
    <li>
        <p style="text-align:justify;"><strong>Grid Search</strong>: This method exhaustively searches through a specified hyperparameter space. While it guarantees finding the best model, it can be computationally expensive and time-consuming, especially with numerous hyperparameters.</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Random Search</strong>: Unlike grid search, random search samples a fixed number of hyperparameter combinations randomly. This approach can be more efficient and often yields comparable results to grid search with less computational cost.</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Bayesian Optimization</strong>: This advanced technique models the performance of the model as a probabilistic function and uses this model to select the most promising hyperparameters to evaluate next. It is particularly effective in reducing the number of evaluations needed to find optimal hyperparameters.</p>
    </li>
</ul>
<p style="text-align:justify;">&nbsp;</p>
<p style="text-align:justify;"><strong>Ensemble Methods in Supervised Learning</strong><br>&nbsp;</p>
<ul>
    <li>
        <p style="text-align:justify;"><strong>Bagging</strong>: This technique involves training multiple models on different subsets of the data and aggregating their predictions. Random Forest is a well-known example of bagging, where multiple decision trees are trained and their outputs are combined to enhance accuracy.</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Boosting</strong>: Boosting focuses on sequentially training models, where each new model attempts to correct the errors made by the previous ones. AdaBoost is a popular boosting algorithm that adjusts the weights of misclassified instances to improve the model's performance.</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Stacking</strong>: This method involves training multiple models and then using another model to combine their predictions. It leverages the strengths of various algorithms to achieve better accuracy.</p>
    </li>
</ul>
<p style="text-align:justify;">&nbsp;</p>
<p style="text-align:justify;"><strong>Unsupervised Learning:&nbsp;</strong></p>
<p style="text-align:justify;">Unsupervised learning involves training algorithms on unlabeled data to discover inherent patterns, structures, or relationships within the data.</p>
<p style="text-align:justify;"><a target="_blank" rel="noopener noreferrer" href="https://cloud.google.com/discover/what-is-unsupervised-learning?hl=en"><strong>Unsupervised machine learning methods</strong></a></p>
<ul>
    <li>
        <p style="text-align:justify;"><strong>Clustering (SVD, K-Meand, SOM &amp; others)</strong></p>
        <ul>
            <li>
                <p style="text-align:justify;"><strong>Exclusive clustering</strong>: Data is grouped in a way where a single data point can only exist in one cluster. This is also referred to as “hard” clustering. A common example of exclusive clustering is the K-means clustering algorithm, which partitions data points into a user-defined number K of clusters.&nbsp;</p>
            </li>
            <li>
                <p style="text-align:justify;"><strong>Overlapping clustering: </strong>Data is grouped in a way where a single data point can exist in two or more clusters with different degrees of membership. This is also referred to as “soft” clustering.&nbsp;</p>
            </li>
            <li>
                <p style="text-align:justify;"><strong>Hierarchical clustering: </strong>Data is divided into distinct clusters based on similarities, which are then repeatedly merged and organized based on their hierarchical relationships. There are two main types of hierarchical clustering: agglomerative and divisive clustering. This method is also referred to as HAC—hierarchical cluster analysis.&nbsp;</p>
            </li>
            <li>
                <p style="text-align:justify;"><strong>Probabilistic clustering: </strong>Data is grouped into clusters based on the probability of each data point belonging to each cluster. This approach differs from the other methods, which group data points based on their similarities to others in a cluster.</p>
            </li>
        </ul>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Association (Apriori, FP-Growth)</strong></p>
        <ul>
            <li>
                <p style="text-align:justify;">Association rule mining is a rule-based approach to reveal interesting relationships between data points in large datasets. Unsupervised learning algorithms search for frequent if-then associations—also called rules—to discover correlations and co-occurrences within the data and the different connections between data objects.&nbsp;</p>
            </li>
            <li>
                <p style="text-align:justify;">Apriori algorithms are the most widely used for association rule learning to identify related collections of items or sets of items. However, other types are used, such as Eclat and FP-growth algorithms.</p>
            </li>
        </ul>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Dimensionality reduction</strong></p>
        <ul>
            <li>
                <p style="text-align:justify;">Dimensionality reduction is an unsupervised learning technique that reduces the number of features, or dimensions, in a dataset. More data is generally better for machine learning, but it can also make it more challenging to visualize the data.</p>
            </li>
            <li>
                <p style="text-align:justify;">Dimensionality reduction extracts important features from the dataset, reducing the number of irrelevant or random features present. This method uses principle component analysis (PCA) and singular value decomposition (SVD) algorithms to reduce the number of data inputs without compromising the integrity of the properties in the original data.</p>
            </li>
        </ul>
    </li>
</ul>
<p style="text-align:justify;">&nbsp;</p>
<p style="text-align:justify;"><strong>Real-world unsupervised learning examples:</strong></p>
<ul>
    <li>
        <p style="text-align:justify;"><strong>Anomaly detection</strong>: Unsupervised clustering can process large datasets and discover data points that are atypical in a dataset.&nbsp;</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Recommendation engines</strong>: Using association rules, unsupervised machine learning can help explore transactional data to discover patterns or trends that can be used to drive personalized recommendations for online retailers.&nbsp;</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Customer segmentation:</strong> Unsupervised learning is also commonly used to generate buyer-persona profiles by clustering customers’ common traits or purchasing behaviors. These profiles can then be used to guide marketing and other business strategies.&nbsp;</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Fraud detection</strong>: Unsupervised learning is useful for anomaly detection, revealing unusual data points in datasets. These insights can help uncover events or behaviors that deviate from normal patterns in the data, revealing fraudulent transactions or unusual behavior like bot activity.&nbsp;</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Natural language processing (NLP)</strong>: Unsupervised learning is commonly used for various NLP applications, such as categorizing articles in news sections, text translation and classification, or speech recognition in conversational interfaces. Genetic research: Genetic clustering is another common unsupervised learning example. Hierarchical clustering algorithms are often used to analyze DNA patterns and reveal evolutionary relationships.&nbsp;<br>&nbsp;</p>
    </li>
</ul>
<p style="text-align:justify;"><strong>Semi-Supervised Learning:</strong></p>
<p style="text-align:justify;">Semi-supervised learning (SSL) is a machine learning technique that uses a small portion of labeled data and lots of unlabeled data to train a predictive model.</p>
<p style="text-align:justify;">Has a limited area of applications (mostly for clustering purposes) and provides less accurate results. We won't be exploring SSL solutions on this repository.</p>
<p style="text-align:justify;">&nbsp;</p>
<p style="text-align:justify;"><strong>Reinforcement Learning:&nbsp;</strong></p>
<p style="text-align:justify;">Reinforcement learning (RL) is a machine learning (ML) technique that trains software to make decisions to achieve the most optimal results. It mimics the trial-and-error learning process that humans use to achieve their goals. Software actions that work towards your goal are reinforced, while actions that detract from the goal are ignored. RL algorithms use a reward-and-punishment paradigm as they process data. They learn from the feedback of each action and self-discover the best processing paths to achieve final outcomes. The algorithms are also capable of delayed gratification. The best overall strategy may require short-term sacrifices, so the best approach they discover may include some punishments or backtracking along the way. RL is a powerful method to help artificial intelligence (AI) systems achieve optimal outcomes in unseen environments.</p>
<p style="text-align:justify;">&nbsp;</p>
<p style="text-align:justify;"><strong>Types of reinforcement learning algorithms:</strong></p>
<ul>
    <li>Model-based RL (well known algorithms):<ul>
            <li>Dynamic Programming (DP)</li>
            <li>Monte Carlo Tree Search (MCTS)</li>
            <li>Temporal Difference (TD) Learning</li>
        </ul>
    </li>
    <li>Model-free RL&nbsp;</li>
</ul>
<p>&nbsp;</p>
<p style="margin-left:0px;"><strong>Neural network (the backbone of deep learning algorithms)</strong>: A neural network of more than three layers, including the inputs and the output, can be considered a deep-learning algorithm.</p>
<p style="margin-left:0px;">&nbsp;</p>
<p style="margin-left:0px;"><a target="_blank" rel="noopener noreferrer" href="https://www.iberdrola.com/innovation/deep-learning"><strong>Deep learning</strong></a> is based on machine learning in order to progressively get a computer to learn on its own and perform human-like tasks, such as image identification, speech recognition or predictions, from a large amount of data and after numerous layers of processing with algorithms.</p>
<p>&nbsp;</p>
<p>APPLICATIONS OF DEEP LEARNING :</p>
<ul>
    <li><strong>Artificial vision</strong>: Artificial vision acquires the ability to recognise characters, images, objects and even faces, and its impact on Industry 4.0, for example, in quality control, will be significant.</li>
    <li><strong>Predictive analysis</strong>: Predictive analysis can generate more accurate forecasts of business results, market developments or energy needs.</li>
    <li><strong>Virtual assistants</strong>: Alexa, Cortana or Siri are assistants that understand and execute the user's voice commands in natural language and are able to learn over time.</li>
    <li>Chatbots</li>
    <li>Robotics</li>
    <li>Health</li>
    <li>Entertainment</li>
    <li><strong>&amp; Others</strong></li>
</ul>
<p>&nbsp;</p>
<p><strong>Most commonly used Deep Learning Algorithms:</strong></p>
<ol>
    <li><strong>Convolutional Neural Networks (CNNs)</strong>
        <ol>
            <li>CNNs are a deep learning algorithm that processes structured grid data like images. They have succeeded in image classification, object detection, and face recognition tasks.</li>
        </ol>
    </li>
    <li><strong>Recurrent Neural Networks (RNNs)</strong>
        <ol>
            <li>RNNs are designed to recognize patterns in data sequences, such as time series or natural language. They maintain a hidden state that captures information about previous inputs.</li>
        </ol>
    </li>
    <li><strong>Long Short-Term Memory Networks (LSTMs)</strong>
        <ol>
            <li>LSTMs are a special kind of RNN capable of learning long-term dependencies. They are designed to avoid the long-term dependency problem, making them more effective for tasks like speech recognition and time series prediction.</li>
        </ol>
    </li>
    <li><strong>Generative Adversarial Networks (GANs)</strong>
        <ol>
            <li>GANs generate realistic data by training two neural networks in a competitive setting. They have been used to create realistic images, videos, and audio.</li>
        </ol>
    </li>
    <li><strong>Transformer Networks</strong>
        <ol>
            <li>Transformers are the backbone of many modern NLP models. They process input data using self-attention, allowing for parallelization and improved handling of long-range dependencies.</li>
        </ol>
    </li>
    <li><strong>Autoencoders</strong>
        <ol>
            <li>Autoencoders are unsupervised learning models for tasks like data compression, denoising, and feature learning. They learn to encode data into a lower-dimensional representation and then decode it back to the original data.</li>
        </ol>
    </li>
    <li><strong>Deep Belief Networks (DBNs)</strong>
        <ol>
            <li>DBNs are generative models composed of multiple layers of stochastic, latent variables. They are used for feature extraction and dimensionality reduction.</li>
        </ol>
    </li>
    <li><strong>Deep Q-Networks (DQNs)</strong>
        <ol>
            <li>DQNs combine deep learning with Q-learning, a reinforcement learning algorithm, to handle environments with high-dimensional state spaces. They have been successfully applied to tasks such as playing video games and controlling robots.</li>
        </ol>
    </li>
    <li><strong>Variational Autoencoders (VAEs)</strong>
        <ol>
            <li>VAEs are generative models that use variational inference to generate new data points similar to the training data. They are used for generative tasks and anomaly detection.</li>
        </ol>
    </li>
    <li><strong>Graph Neural Networks (GNNs)</strong></li>
</ol>
<p>&nbsp;</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://preset.io/blog/time-series-forecasting-a-complete-guide/"><strong>Time-Series</strong></a></p>
<p>Time series forecasting refers to the practice of examining data that changes over time, then using a statistical model to predict future patterns and trends.</p>
<p><strong>Components of time series forecasting models</strong><br>&nbsp;</p>
<ul>
    <li><strong>Trend</strong>: Increase or decrease in the series of data over longer a period.</li>
    <li><strong>Seasonality</strong>: Fluctuations in the pattern due to seasonal determinants over a period such as a day, week, month, season.</li>
    <li><strong>Cyclical variations</strong>: Occurs when data exhibit rises and falls at irregular intervals.</li>
    <li><strong>Random or irregular variations</strong>: Instability due to random factors that do not repeat in the pattern.</li>
</ul>
<p>&nbsp;</p>
<p>Top algorithms for Time forecasting:&nbsp;</p>
<p>&nbsp;</p>
<ul>
    <li>Autoregressive (AR): An autoregressive (<strong>AR</strong>) model predicts future behaviour based on past behaviour. It’s used for forecasting when there is some correlation between values in a time series and the values that precede and succeed them.</li>
    <li>Autoregressive Integrated Moving Average (<strong>ARIMA</strong>): Auto Regressive Integrated Moving Average, ARIMA, models are among the most widely used approaches for time series forecasting. It is actually a class of models that ‘explains’ a given time series based on its own past values, that is, its own lags and the lagged forecast errors, so that equation can be used to forecast future values.</li>
    <li>Seasonal Autoregressive Integrated Moving Average (<strong>SARIMA</strong>): Seasonal autoregressive integrated moving average (SARIMA) models extend basic ARIMA models and allow for the incorporation seasonal patterns.</li>
    <li>Exponential Smoothing (<strong>ES</strong>): Exponential smoothing is a time series forecasting method for univariate data that can be extended to support data with a systematic trend or seasonal component.</li>
    <li><strong>Prophet</strong>: Prophet, which was released by Facebook’s Core Data Science team, is an open-source library developed by Facebook and designed for automatic forecasting of univariate time series data.</li>
    <li>LSTM: Long Short-Term Memory (<strong>LSTM</strong>) is a type of recurrent neural network that can learn the order dependence between items in a sequence. It is often used to solve time series forecasting problems.</li>
    <li>DeepAR: <strong>DeepAR </strong>developed by Amazon is a probabilistic forecasting model based on autoregressive recurrent neural networks.</li>
    <li>N-BEATS: <strong>N-BEATS </strong>is a custom Deep Learning algorithm which is based on backward and forward residual links for univariate time series point forecasting.</li>
    <li>Temporal Fusion Transformer (Google): A novel attention-based architecture which combines high-performance multi-horizon forecasting with interpretable insights into temporal dynamics.</li>
</ul>
<h5 style="text-align:justify;">5. Evaluation</h5>
<p style="text-align:justify;"><br>&nbsp;This step depends majorly on the previous steps defined. Here, we need to find the correct methodology to analyze if our model has the results that we are expecting. This step can be defined in 3 parts:&nbsp;</p>
<p style="text-align:justify;">&nbsp;</p>
<ol>
    <li>
        <p style="text-align:justify;"><strong>Evaluate results</strong> by assessing the degree to which model meets the objective of the business and testing the models on test applications if time and budget permit.</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Review Process</strong> by conducting a more thorough review of the data mining engagement to determine if there is any important factor or task that has somehow been overlooked during the process, identify any quality assurance issues, and summarize the process review and highlight activities that have been missed and/or should be repeated.</p>
    </li>
    <li>
        <p style="text-align:justify;"><strong>Determine next Steps</strong> by assessing how to proceed with the project. In this part, listing potential further actions along with the reason for and against each option and describing how to proceed is important.</p>
    </li>
</ol>
<p style="text-align:justify;">&nbsp;</p>
<p style="text-align:justify;"><strong>New topic: </strong><a target="_blank" rel="noopener noreferrer" href="https://www.databricks.com/blog/introduction-time-series-forecasting-generative-ai"><strong>Time Series Forecasting with Generative AI</strong></a></p>
<h5 style="text-align:justify;">6. Deployment<br>&nbsp;</h5>
<p style="text-align:justify;">I'll leave this part for another time. But here you have some ideas on how you can explore deployment of data mining projects:</p>
<ul>
    <li>
        <p style="text-align:justify;"><a target="_blank" rel="noopener noreferrer" href="https://django-machine-learning-user-interface">Django-machine-learning-user-interface</a></p>
    </li>
    <li><a target="_blank" rel="noopener noreferrer" href="https://towardsdatascience.com/build-an-awesome-ui-for-your-machine-learning-models-7fab52ecdd86">Gradio</a><br>&nbsp;</li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
